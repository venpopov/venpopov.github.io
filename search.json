[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Computational thinking",
    "section": "",
    "text": "Open Science needs reliable infrastructure\n\n\nA Postmortem on the OSF Redesign Incident\n\n\n\nopen science\n\n\nreproducibility\n\n\nacademic publishing\n\n\n2025\n\n\n\nAfter OSF‚Äôs October 2025 redesign, I discovered that eight years of DOI-linked preprints and materials were silently hidden by an automated spam flag. What happened, how it was resolved, and what it reveals about trust in open science infrastructure.\n\n\n\n\n\nNov 6, 2025\n\n\n18 min\n\n\n\n\n\n\n\nR love you, R hate you\n\n\n\n\n\n\nR\n\n\nprogramming\n\n\n2025\n\n\n\n\n\n\n\n\n\nFeb 21, 2025\n\n\n12 min\n\n\n\n\n\n\n\naRt-o Pollo\n\n\n\n\n\n\nR\n\n\nart\n\n\n2025\n\n\n\n\n\n\n\n\n\nFeb 21, 2025\n\n\n11 min\n\n\n\n\n\n\n\nReduce friction for creating Quarto blog posts\n\n\nI teach myself how to code simple shell scripts to automate some annoying tasks\n\n\n\nworkflow\n\n\nshell\n\n\n2024\n\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\n6 min\n\n\n\n\n\n\n\nRethinking my approach to computational projects and reproducibility\n\n\nThere has to be a better way\n\n\n\nworkflow\n\n\nreproducibility\n\n\nR\n\n\ngit\n\n\ntargets\n\n\nproject management\n\n\n2024\n\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\n9 min\n\n\n\n\n\n\n\nTaking a stand on open peer review\n\n\nI will no longer review for journals that do not publish reviews alongside the work\n\n\n\nacademic publishing\n\n\npeer review\n\n\nopen science\n\n\n2024\n\n\n\n\n\n\n\n\n\nAug 4, 2024\n\n\n2 min\n\n\n\n\n\n\n\nIntroducing the Bayesian Measurement Modeling R Package (bmm)\n\n\nMaking Bayesian measurement modeling in psychology accessible, reliable & efficient\n\n\n\nR\n\n\nmodeling\n\n\nbayesian\n\n\nR package\n\n\n2024\n\n\n\n\n\n\n\n\n\nJun 13, 2024\n\n\n14 min\n\n\n\n\n\n\n\nLocally Ignoring Git Files Without Affecting Others‚Äô .gitignore\n\n\nHow to exclude files from version control without affecting other developers‚Äô .gitignore configuration\n\n\n\ngit\n\n\nGitHub\n\n\nreproducibility\n\n\nworkflow\n\n\ncollaboration\n\n\n2024\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\n4 min\n\n\n\n\n\n\n\nWorking with multiple versions of an R package\n\n\nAfter being dissatisfied with existing solutions, I wrote a package to do that\n\n\n\nR\n\n\nreproducibility\n\n\npackage management\n\n\nR package\n\n\n2024\n\n\n\n\n\n\n\n\n\nMar 3, 2024\n\n\n7 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html",
    "title": "Open Science needs reliable infrastructure",
    "section": "",
    "text": "In October 2025, a redesign of the Open Science Framework (OSF) led to widespread access failures across the platform. What began as a few broken download links became, in my case, a total disappearance of eight years of DOI-registered work. This is the story of what happened, how it was resolved, and what it reveals about trust and infrastructure in open science."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#widespread-glitches",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#widespread-glitches",
    "title": "Open Science needs reliable infrastructure",
    "section": "Widespread glitches",
    "text": "Widespread glitches\nOn October 11th, 2025, the Center for Open Science (COS) announced that the Open Science Framework ‚Äî its flagship platform for preprints, data, and code ‚Äî had received a major redesign. The update promised ‚Äúto make managing research projects easier, faster, and more intuitive.‚Äù\nWithin days, many discovered that the new redesign ironically came with slower loading times, but more troubling, with a host of bugs and glitches:\n\n\nPSA: seems like the update broke the ability to directly download files with a link, like osf.io/XXXX/download this lead to an error in one of my R package vignettes, and presumably will break lots of code.[image or embed]\n\n‚Äî Ruben C. Arslan (@ruben.the100.ci) October 12, 2025 at 10:34 AM\n\n\n\nThanks. I think this is urgent. I suspect it also broke Google Scholar listing PDFs from OSF, at least I get broken links for some, no links for others and generally OSF seems to be massively downranked in the list of sources. Started getting email requests for PDFs again.\n\n‚Äî Ruben C. Arslan (@ruben.the100.ci) October 16, 2025 at 11:43 AM\n\n\n\n@cos.io Why cant I read in rds files from my repo? I was trying to reproduce my manuscript and now I cant read in rds files from the site. I am going to assume it has to do with the new UI?\n\n‚Äî jgeller1phd.bsky.social (@jgeller1phd.bsky.social) October 11, 2025 at 5:57 PM\n\n\n\nIs anyone else experiencing significant issues (lags, not loading) with OSF (@cos.io) since the interface update?\n\n‚Äî Charlotte Pennington üåª (@drcpennington.bsky.social) October 22, 2025 at 7:51 PM\n\n\n\nü™≤ OSF Update: Ongoing Fixes Following the OSF redesign, some issues have been identified:\n\nSome custom registry templates may not showall fields\nOSF shows a max. of 10 contributors\nSome pages load slowly or seem unresponsive\n\nThese are on our critical fix list & should be resolved soon. (1/2)\n\n‚Äî Center for Open Science (@cos.io) October 17, 2025 at 7:46 PM\n\n\n\nAlso, - Login screen doesn‚Äôt work on Safari - Preregistrations impossible (got many error messages & after I was finally able to submit got an email saying trouble archiving my preregistration so it wasn‚Äôt completed)‚Ä¶ this means I can‚Äôt actually run my study :( - Symbols not rendering (e.g., &, &lt;)\n\n‚Äî Cassandra Chapman (@cassandrachapman.bsky.social) October 22, 2025 at 11:38 PM\n\n\nI do not mention complaints about design, as those are subjective. But it was worrisome that a redesign would break existing download link patterns without a redirect - this should not happen to an archival service. To their credit, COS fixed that particular problem quickly, though it should never needed fixing in the first place. The performance issues remain, and the irony that this performance update made performance worse is not lost to anyone. What seemed like transitional friction soon turned into something stranger."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-disappearance",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-disappearance",
    "title": "Open Science needs reliable infrastructure",
    "section": "The Disappearance",
    "text": "The Disappearance\nOn November 2, I realized that none of my OSF preprints would open. Every single one ‚Äî roughly twenty projects spanning eight years ‚Äî returned either a blank page with a red banner reading ‚ÄúNot found‚Äù or a JSON message declaring the resource ‚Äúdeleted by the user.‚Äù\nAt first, I assumed it was a global outage consistent with the widespread performance issues mentioned above. But when I double checked, the pattern was unmistakable:\n\nOther authors‚Äô preprints worked fine.\nThe error appeared for every preprint and dataset linked to my name ‚Äî including one uploaded by a colleague just four days earlier.\nEven Google Scholar links that had functioned for years now led to ‚ÄúResource deleted‚Äù errors:\n\n{\"message_short\": \"Resource deleted\", \"message_long\": \"User has deleted this content. If this should not have occurred and the issue persists, please report it to &lt;a href=\\\"mailto:support@osf.io\\\"&gt;support@osf.io&lt;\\/a&gt;.\", \"code\": 410, \"referrer\": null}\nMost worrisome of all - the ‚Äúblackout‚Äù included files linked in published journal articles and materials for projects currently under ¬†peer review.\nI reported the issue to OSF support with screenshots and links, expecting acknowledgment that something had gone wrong with the migration:\n\n&lt;On Nov 2, 2025 at 23:40 +0100, Ven Popov, wrote:&gt;\nI am experiencing a serious issue with my preprints on OSF. At first I thought this was a global OSF issue, but it seems like it is affecting all and only my preprints, which makes me very concerned.\nWhen I try to access any of the preprints on which I am a co-author, I get an error.\nIf I try to access the preprint via and OSF url, I get a blank page with a red banner ‚ÄúNot found‚Äù (see attached screenshot). Examples:\n\nhttps://osf.io/yr9xb\nhttps://osf.io/gwd4s\nhttps://osf.io/hmu9r\nhttps://osf.io/dsx6y\nhttps://osf.io/vj8pn (this one was uploaded only 4 days ago by a colleague!)\n\nIf I try to access the PDF links on Google Scholar (e.g.¬†this link), I get the following JSON error message:\n[‚Ä¶]\nI tested this with all ~20 preprints listed on my profile and I get the error on all of them. When I try to open any other preprint that is not authored by me, I can open it just fine. I‚Äôd appreciate any assistance with resolving this issue.\n\nInstead, I was asked to fill out a form for ‚Äúaccounts flagged as spam.‚Äù\n\n&lt; On Mon, Nov 3, 2025 at 7:30 AM EST, Blaine Support support@osf.io wrote:&gt;\nIf you received this email, it means that we need your assistance in investigating your account. Please help us by providing more information through this form: Account Disabled or Falsely Flagged as SPAM reporting. If we don‚Äôt receive your form submission, we won‚Äôt be able to investigate the issue. Your input is invaluable as we work to improve our spam detection systems."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-support-loop",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-support-loop",
    "title": "Open Science needs reliable infrastructure",
    "section": "The Support Loop",
    "text": "The Support Loop\nI filled out the spam-flag form, though I knew my account was active and clean. I was logged into my account and could change my account information. I could also see all my project listings, though not the details. I replied back:\n\n&lt; On Mon, Nov 3, 2025 at 7:47 AM EST, Ven Popov, wrote:&gt;\nI filled out the form, but my account is neither deactivated nor flagged as SPAM. I simply cannot access any of the 20+ preprints that I or my colleagues have uploaded over the last 8 years! In the form I supplied a link to one preprint, but all of my preprints are inaccessible.\n\nA few hours later I received a message from a new support representative, asking me again to fill out the same form:\n\n&lt; On Nov 3, 2025 at 16:04 +0100, Michaela Support support@osf.io, wrote:&gt;\nPlease fill out the form: Account Disabled or Falsely Flagged as SPAM reporting. Your preprint have been flagged as spam. This is an important step in tracking how effective (or not) our spam filters are, and to review and resolve the issue.\n\nFrustrated, I copied Brian Nosek on a detailed escalation email explaining that this was not a single-ticket problem but a catastrophic integrity failure: twenty preprints, hundreds of files, dozens of co-authors, and years of published work were all inaccessible. It was not one ‚Äúpreprint flagged as spam.‚Äù Anything I ‚Äî or anyone associated with me ‚Äî had uploaded since 2017 was completely inaccessible, and OSF was effectively communicating to the world that this work no longer existed.\n\n&lt;On Nov 3, 2025 at 16:45 +0100, Ven Popov, wrote:&gt;\nAs I replied in my previous email, I already filled out the form.\nFurthermore, it is not one preprint that is inaccessible. All of the 20+ preprints that I have published on OSF since 2017 are unavailable. Neither the OSF links from my profile, nor the Google Scholar links that have worked for years can be opened.\nPlease escalate this issue. This is a serious misstep on OSF‚Äôs part. I have had an account with OSF for 8 years, I have published about 20 preprints during this time, and none of them are available. For some of them, the OSF links might be the only record online of these published works, and it is a serious issue concerning the longevity of scholarship that an archival platform like OSF cannot allow to happen.\n@Brian, can you please get your support team to take this seriously? I‚Äôm getting repeated emails asking me to do something I already did and overlooking the extent of the problem. Please see the message history for the detailed report and links to my profile, a subset of broken preprint links, and an API error from Google Scholar links.\n\nWithin hours, OSF staff identified the cause: my account had been automatically flagged as spam by their filters. Once the flag was removed, everything reappeared."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-explanation",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-explanation",
    "title": "Open Science needs reliable infrastructure",
    "section": "The Explanation",
    "text": "The Explanation\nHere‚Äôs the message I received:\n\n&lt; On Nov 3, 2025 at 19:31 +0100, Michaela Support support@osf.io, wrote&gt;\nThank you for reaching out to the OSF support team! You are correct it looks like your project was caught in our spam filter. As a free open access platform we are frequently the target of spammers, and therefore we must use multiple different spam filters that take a plethora of different factors into account when flagging spam, everything from odd titles to suspicious activity from a nearby IP address could get flagged. Truthfully it‚Äôs hard to tell why your content got its attention. I‚Äôm sorry for the inconvenience. I‚Äôve removed the flag from material and your content should be active again!\n\nIt was an honest reply ‚Äî but also a disturbing one.\nOSF‚Äôs filters had quarantined everything I or any of my colleagues had ever uploaded, without warning, without a visible flag on my dashboard, and without preserving any metadata or landing pages. Public DOIs and Google Scholar entries now pointed to HTTP 410 ‚ÄúResource deleted‚Äù responses ‚Äî a code that explicitly signals permanent removal to search engines.\nIn other words, for several days, OSF‚Äôs infrastructure told the world that our work no longer existed."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-deeper-problem",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#the-deeper-problem",
    "title": "Open Science needs reliable infrastructure",
    "section": "The Deeper Problem",
    "text": "The Deeper Problem\nThis incident isn‚Äôt about data loss ‚Äî most of my materials were mirrored elsewhere. The issue is trust.\nResearchers use OSF because it promises persistence. It issues DOIs, integrates with journals, and serves as part of the scholarly record. That promise was violated ‚Äî not through malice, but through a structural design choice: an automated filter was allowed to silently deindex archival content.\nSpam detection is necessary. But a true archive must never delete first and explain later. An archive is defined by its immutability and accountability.\nThe design flaw wasn‚Äôt that a spam flag existed ‚Äî it‚Äôs that its activation could unpublish a decade‚Äôs worth of DOI-assigned material without human review, notification, or even the retention of metadata.\nThis episode highlights a broader fragility in the open science ecosystem. The infrastructure of modern scholarship ‚Äî repositories, indexing services, DOI registries ‚Äî runs on trust. When that infrastructure silently fails, the damage is epistemic: we lose not just access to data, but confidence in the permanence of the scientific record.\nAn archival platform must therefore:\n\nRetain metadata and landing pages even when content is quarantined.\nNotify users when materials are flagged or hidden\nRequire human verification before suppressing DOI-linked material.\nUse non-destructive HTTP codes for temporary removals.\n\nThese are not minor UX fixes ‚Äî they are the foundations of reliability in digital scholarship. I made this much clear in an email reply:\n\n&lt;On Mon, Nov 3, 2025 at 2:26‚ÄØPM Ven Popov wrote:&gt;\nThank you for resolving the issue and restoring access to my materials. I understand that OSF, as a free and open platform, must protect itself against spam.\nHowever, the way your spam-filtering system currently operates is unacceptable and incompatible with OSF‚Äôs stated mission as an archival repository. Automatically blocking access to more than twenty DOI-registered preprints, datasets, and supplementary materials spanning nearly a decade ‚Äî including work co-authored by dozens of researchers and cited in published papers ‚Äî is not a minor glitch. It constitutes a violation of the very FAIR principles OSF promotes and undermines trust in your platform as part of the scholarly record.\nWorse, the system suppressed all metadata and landing pages, returning an HTTP 410 ‚ÄúResource deleted‚Äù response. That code explicitly signals to search engines that a resource has been permanently removed and should be de-indexed. This means the issue not only disrupted access but actively damaged the discoverability and citation continuity of legitimate research outputs.\nI fully support the need for robust spam protection. But the current implementation ‚Äî silent removal of legitimate archival content, without notice or human verification, and with a response that signals permanent deletion ‚Äî is deeply inconsistent with COS‚Äôs commitments to openness, transparency, and persistence.\nI urge COS to review this policy and implement safeguards such as:\n\nHuman review before suppressing any DOI-assigned or public scholarly record.\nRetention of metadata and landing pages for any quarantined content.\nClear notifications to affected users.\nUse of non-destructive HTTP status codes (e.g., 451 or 503) for temporary suppression.\n\nThese are not just usability issues; they concern the credibility of OSF as a reliable component of the scientific infrastructure.\nI am deeply troubled by this incident, and I do not say this lightly. I have been a staunch supporter of COS and its mission for years. But this event exposes an infrastructural weakness that seriously undermines trust in the OSF platform.\nI would appreciate a response from COS leadership that demonstrates an understanding of the gravity of this failure and provides a clear plan to prevent similar occurrences in the future.\nI intend to publish this correspondence publicly, and I hope that I can do so alongside a response that acknowledges these concerns and reaffirms COS‚Äôs commitment to openness, transparency, and durability in scientific communication."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#aftermath",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#aftermath",
    "title": "Open Science needs reliable infrastructure",
    "section": "Aftermath",
    "text": "Aftermath\nAfter I sent my detailed critique, Brian Nosek responded personally and with grace. He acknowledged that this case was unprecedented, thanked me for the thorough documentation, and assured me that it would help the team identify whether others had been similarly affected.\n\n&lt; On Nov 3, 2025 at 22:05 +0100, Brian Nosek, wrote:&gt;\nI see from the¬†thread that your issue is resolved, but I am sorry that you had to go through that!\nI really appreciate the detailed notes that you provided to help identify the source of the problem, and even more the solutioning that you offered to improve user experience and more gracefully manage the identification and mitigation of spam. I have not heard of a case like this, so while it was a painful experience that you had to deal with, hopefully the exposure of the problem with your diligent reporting will help us to identify the extent to which it is occurring more widely and develop effective solutions.\nThanks again for giving us such useful reporting on your experience with this to help us continue to improve the service.\n\nDespite this response, I was still deeply troubled. I briefly considered whether I‚Äôm overreacting. After consulting several colleagues, they were unanimous: the severity is not that it happened to me, but that it could happen at all ‚Äî silently and retroactively. As one colleague put it:\n\nI agree, I think the issue is more severe than it sounds like. The effect is crazy to me. Not only that they retrospectively delete the stuff but also how many people can be affected by it. It‚Äôs already severe in your case with a large network of collaborators. But imagine Klaus‚Äôs account gets flagged and he doesn‚Äôt realize it. This would probably take hundreds of preprints offline, which are primary the work of others [junior researchers]. It‚Äôs bad enough that they take the stuff down that you put on OSF but it also deletes the work where someone else just linked your name with? This also can‚Äôt be right‚Ä¶\n\nAfter some reflection, I followed up with Brian Nosek with a longer message explaining why the issue mattered so deeply: not because of personal inconvenience, but because silent retroactive suppression of long-standing records is incompatible with the role of an archive.\n\n&lt; On Nov 4, 2025 at 13:49 +0100, Ven Popov wrote:&gt;\nThank you for the thoughtful response. I appreciate that you will take this case seriously in developing future solutions.\nI just really want to stress why I am so concerned about this having happened. It‚Äôs not about my work and that it affected me personally, although that clearly made me more motivated to get to the bottom of it. My work is also backed up on other platforms, including ResearchGate, a University of Zurich repository and my personal website. The real problem is that something like this should not be possible to happen in the first place, let alone as the result of an automated filter.\nWhatever the reason my account was flagged, an automated filter should never have the authority to retroactively block access to the work of hundreds of researchers simply because I‚Äôm listed as a co-author. These were not new uploads but materials that had been part of the scholarly record for nearly a decade.\nI was lucky to notice the disappearance within days; others might not. Under different circumstances, months could have passed during which all these digital objects appeared effectively erased. The consequences for more prominent researchers with hundreds of linked projects - and for junior collaborators relying on those links - could be far more severe.\nYour own guidelines stress that even authors themselves cannot delete accepted preprints - that preprints can only be withdrawn, and that the associated metadata and reasons for withdrawn will always remain part of the record.\nI considered whether I might be overreacting, but after discussing the issue with several colleagues, everyone agrees that this is a critical infrastructure-level bug. This requires more than a patch for this particular case, but systems in place to ensure that nothing can in principle cause something like it to happen in the future.\nI am writing all this out in detail not to attack COS or its work on maintaining OSF. It‚Äôs exactly the opposite - I share all COS values and view it as a fundamentally important institution. The traditional academic publishing system is rotten to core, but in order for any reform to succeed long-term, people must trust the infrastructure and systems in place. I want to see COS and OSF continue to succeed and continue to play the vital role that it has attained. This is why I am being so adamant about this incident being taken so seriously.\n\nHis reply was thoughtful and for the moment I am satisfied that this incident will be taken seriously:\n\n&lt;On Nov 4, 2025 at 14:45 +0100, Brian Nosek, wrote:&gt;\nThanks for the follow-up. There is nothing inappropriate at all about your comments or approach. It is very clear that your comments are made in good faith to help us improve the services and meet the aspirations of reliable, persistent open scholarship. We truly appreciate your willingness to put time into documenting and sharing the challenges you experienced here.\n\nThat, to me, felt like the right place to stop. Ideally, I‚Äôd still like an official statement from COS about what they plan to do to ensure that something like this doesn‚Äôt happen again."
  },
  {
    "objectID": "posts/2025/open-science-needs-reliable-infrastructure/index.html#data-vs.-trust",
    "href": "posts/2025/open-science-needs-reliable-infrastructure/index.html#data-vs.-trust",
    "title": "Open Science needs reliable infrastructure",
    "section": "Data vs.¬†Trust",
    "text": "Data vs.¬†Trust\nNo data were ultimately lost. But something far more important was at stake: the continuity of the scholarly record.\nIf this episode serves any purpose, let it be a reminder that openness is not just about making information accessible ‚Äî it‚Äôs about ensuring it stays accessible. Scientific infrastructure must be engineered for trustworthiness, not just availability.\nAs we argued in a recent perspective paper, the traditional publishing system is rotten to the core. But for any reform to succeed long-term, people must trust the infrastructure and systems in place.\nI also don‚Äôt know if this incident is related to the OSF redesign - I described it here within that context - or whether it would have occurred with the previous platform. Ultimately it doesn‚Äôt matter.\nTrust is slow to earn and quick to erode. I hope OSF uses this experience to reinforce that trust ‚Äî not only by fixing the bug, but by institutionalizing the safeguards that make open scholarship durable."
  },
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Curriculum vit√¶",
    "section": "",
    "text": "Download current CV"
  }
]